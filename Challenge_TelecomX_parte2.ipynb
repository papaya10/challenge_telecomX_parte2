{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSq0g-j8w0gA"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# TELECOM X - PARTE 2 (PREDICCI√ìN DE CHURN) - NOTEBOOK COLAB\n",
        "# ============================================================\n",
        "\n",
        "# (0) OPCIONAL: instala librer√≠as extra si las necesitas\n",
        "# Quita los \"!\" si ya las tienes en tu entorno local\n",
        "!pip install -q imbalanced-learn xgboost\n",
        "\n",
        "# (1) IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGB_AVAILABLE = True\n",
        "except:\n",
        "    XGB_AVAILABLE = False\n",
        "\n",
        "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
        "\n",
        "print(\"‚úÖ Librer√≠as cargadas. XGBoost disponible:\", XGB_AVAILABLE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) CARGA DE DATOS\n",
        "# Elige UNA de estas opciones:\n",
        "\n",
        "# Opci√≥n A: cargar desde un CSV en GitHub (enlace RAW)\n",
        "# data_url = \"https://raw.githubusercontent.com/TU_USUARIO/TU_REPO/main/data/processed/telecom_churn_clean.csv\"\n",
        "# df = pd.read_csv(data_url)\n",
        "\n",
        "# Opci√≥n B: subir el CSV desde tu PC a Colab\n",
        "from google.colab import files\n",
        "print(\"Sube tu CSV (ej: telecom_churn_clean.csv) con la columna objetivo 'Churn'\")\n",
        "uploaded = files.upload()\n",
        "csv_name = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(csv_name)\n",
        "\n",
        "print(\"‚úÖ Datos cargados con forma:\", df.shape)\n",
        "display(df.head())\n",
        "display(df.sample(5))\n"
      ],
      "metadata": {
        "id": "OHbrrcu_xCqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) LIMPIEZA B√ÅSICA Y AJUSTES COMUNES DEL DATASET TELCO\n",
        "\n",
        "# 3.1. Estandarizar nombre de la columna objetivo si viene como \"Churn\", \"churn\", etc.\n",
        "target_candidates = [c for c in df.columns if c.lower() == \"churn\"]\n",
        "if len(target_candidates) == 0:\n",
        "    raise ValueError(\"No se encontr√≥ la columna objetivo 'Churn'. Ren√≥mbrala o ajusta el c√≥digo.\")\n",
        "TARGET = target_candidates[0]  # nombre real en el df\n",
        "\n",
        "# 3.2. Convertir 'Churn' a 0/1 si est√° como texto (Yes/No, Si/No, True/False)\n",
        "def to_binary(x):\n",
        "    if str(x).lower() in [\"yes\", \"si\", \"true\", \"1\"]:\n",
        "        return 1\n",
        "    elif str(x).lower() in [\"no\", \"false\", \"0\"]:\n",
        "        return 0\n",
        "    # fallback: intenta convertir a int\n",
        "    try:\n",
        "        return int(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[TARGET] = df[TARGET].apply(to_binary)\n",
        "\n",
        "# 3.3. Manejo com√∫n del dataset Telco: TotalCharges a num√©rico si existe\n",
        "for col in df.columns:\n",
        "    if col.lower() == \"totalcharges\":\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "# 3.4. Eliminar filas con target faltante\n",
        "df = df.dropna(subset=[TARGET]).copy()\n",
        "\n",
        "# 3.5. Eliminar columnas ID si existen (no informativas)\n",
        "id_like = [c for c in df.columns if \"id\" in c.lower()]\n",
        "df = df.drop(columns=id_like, errors=\"ignore\")\n",
        "\n",
        "print(\"‚úÖ Limpieza b√°sica hecha. Forma:\", df.shape)\n",
        "display(df.head())\n"
      ],
      "metadata": {
        "id": "Ynwctkk2xE3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) EDA R√ÅPIDO (Exploratorio)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# Distribuci√≥n de la variable objetivo\n",
        "df[TARGET].value_counts().plot(kind=\"bar\", ax=axes[0])\n",
        "axes[0].set_title(\"Distribuci√≥n de Churn (0=No, 1=S√≠)\")\n",
        "axes[0].set_xlabel(\"Churn\")\n",
        "axes[0].set_ylabel(\"Conteo\")\n",
        "\n",
        "# Cargos mensuales si existe\n",
        "mch = [c for c in df.columns if c.lower() == \"monthlycharges\"]\n",
        "if mch:\n",
        "    df[mch[0]].hist(ax=axes[1], bins=30)\n",
        "    axes[1].set_title(\"Distribuci√≥n de Cargos Mensuales\")\n",
        "    axes[1].set_xlabel(\"Cargos Mensuales\")\n",
        "    axes[1].set_ylabel(\"Frecuencia\")\n",
        "else:\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top correlaciones con el target (num√©ricas)\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if len(num_cols) > 1:\n",
        "    corr = df[num_cols].corr()[TARGET].sort_values(ascending=False)\n",
        "    print(\"üîé Correlaci√≥n con 'Churn' (num√©ricas):\")\n",
        "    display(corr)\n"
      ],
      "metadata": {
        "id": "ekRHwbtmxGRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) SEPARAR VARIABLES Y TIPO DE DATOS\n",
        "X = df.drop(columns=[TARGET]).copy()\n",
        "y = df[TARGET].astype(int)\n",
        "\n",
        "# Detectar categ√≥ricas y num√©ricas autom√°ticamente\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "print(\"üìé Categ√≥ricas:\", cat_cols[:10], \"...\" if len(cat_cols) > 10 else \"\")\n",
        "print(\"üî¢ Num√©ricas:\", num_cols[:10], \"...\" if len(num_cols) > 10 else \"\")\n",
        "\n",
        "# Train / Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "print(\"‚úÖ Split listo. Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "J1jIjo5HxHCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) PREPROCESAMIENTO (imputaci√≥n + encoding + escalado)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "E9hogyh9xJXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (7) ENTRENAR MODELOS BASE (sin tuning), con SMOTE para desbalance\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=200, n_jobs=None if hasattr(LogisticRegression, \"n_jobs\") else None),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "}\n",
        "if XGB_AVAILABLE:\n",
        "    models[\"XGBoost\"] = XGBClassifier(\n",
        "        n_estimators=400, max_depth=4, learning_rate=0.08, subsample=0.9, colsample_bytree=0.9,\n",
        "        eval_metric=\"logloss\", random_state=42\n",
        "    )\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, clf in models.items():\n",
        "    pipe = ImbPipeline(steps=[\n",
        "        (\"pre\", preprocessor),\n",
        "        (\"smote\", SMOTE(random_state=42)),\n",
        "        (\"model\", clf)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    if hasattr(pipe.named_steps[\"model\"], \"predict_proba\"):\n",
        "        y_proba = pipe.predict_proba(X_test)[:,1]\n",
        "        auc = roc_auc_score(y_test, y_proba)\n",
        "    else:\n",
        "        # Si no hay predict_proba, aproximamos con predicciones binarias\n",
        "        y_proba = None\n",
        "        auc = np.nan\n",
        "\n",
        "    rpt = classification_report(y_test, y_pred, output_dict=True)\n",
        "    results[name] = {\n",
        "        \"pipeline\": pipe,\n",
        "        \"report\": rpt,\n",
        "        \"auc\": auc,\n",
        "        \"pred\": y_pred,\n",
        "        \"proba\": y_proba\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüß† Modelo: {name}\")\n",
        "    print(pd.DataFrame(rpt).round(3))\n",
        "    print(\"AUC:\", round(auc, 4))\n"
      ],
      "metadata": {
        "id": "p7ZMKFVfxKmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (8) MATRICES DE CONFUSI√ìN Y ROC\n",
        "fig, axes = plt.subplots(1, len(results), figsize=(6*len(results), 4))\n",
        "\n",
        "if len(results) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for ax, (name, res) in zip(axes, results.items()):\n",
        "    cm = confusion_matrix(y_test, res[\"pred\"])\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, ax=ax)\n",
        "    ax.set_title(f\"Matriz de Confusi√≥n - {name}\")\n",
        "    ax.set_xlabel(\"Predicci√≥n\")\n",
        "    ax.set_ylabel(\"Real\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ROC\n",
        "plt.figure(figsize=(6,4))\n",
        "for name, res in results.items():\n",
        "    if res[\"proba\"] is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, res[\"proba\"])\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={res['auc']:.3f})\")\n",
        "plt.plot([0,1], [0,1], \"--\", alpha=0.5)\n",
        "plt.title(\"Curvas ROC\")\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iEwczecGxMCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (9) TUNING R√ÅPIDO DEL MEJOR MODELO (opcional)\n",
        "# Elegimos el que tenga mayor AUC inicial\n",
        "best_name = max(results, key=lambda k: (results[k][\"auc\"] if not np.isnan(results[k][\"auc\"]) else -1))\n",
        "print(\"üèÜ Mejor modelo inicial por AUC:\", best_name)\n",
        "\n",
        "best_pipe = results[best_name][\"pipeline\"]\n",
        "\n",
        "# Definimos una grilla peque√±a seg√∫n el modelo\n",
        "param_grid = {}\n",
        "if best_name == \"LogisticRegression\":\n",
        "    param_grid = {\n",
        "        \"model__C\": [0.1, 1.0, 2.0],\n",
        "        \"model__penalty\": [\"l2\"],\n",
        "        \"model__solver\": [\"lbfgs\"]\n",
        "    }\n",
        "elif best_name == \"RandomForest\":\n",
        "    param_grid = {\n",
        "        \"model__n_estimators\": [300, 500],\n",
        "        \"model__max_depth\": [None, 8, 12],\n",
        "        \"model__min_samples_split\": [2, 5]\n",
        "    }\n",
        "elif best_name == \"XGBoost\" and XGB_AVAILABLE:\n",
        "    param_grid = {\n",
        "        \"model__n_estimators\": [300, 500],\n",
        "        \"model__max_depth\": [3, 4, 6],\n",
        "        \"model__learning_rate\": [0.05, 0.1],\n",
        "        \"model__subsample\": [0.8, 1.0]\n",
        "    }\n",
        "\n",
        "if param_grid:\n",
        "    grid = GridSearchCV(\n",
        "        estimator=best_pipe,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"f1\",  # puedes usar \"roc_auc\" o \"f1\"\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    tuned = grid.best_estimator_\n",
        "    y_pred = tuned.predict(X_test)\n",
        "    y_proba = tuned.predict_proba(X_test)[:,1] if hasattr(tuned.named_steps[\"model\"], \"predict_proba\") else None\n",
        "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
        "\n",
        "    print(\"üîß Mejores par√°metros:\", grid.best_params_)\n",
        "    print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).round(3))\n",
        "    print(\"AUC (tuned):\", round(auc, 4))\n",
        "\n",
        "    best_pipe = tuned\n",
        "else:\n",
        "    print(\"Sin grid de par√°metros para este modelo o XGBoost no disponible.\")\n"
      ],
      "metadata": {
        "id": "V70BTRJSxNeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (10) IMPORTANCIA DE VARIABLES (si el modelo lo permite)\n",
        "# Nota: para modelos con OneHotEncoder, las columnas se expanden.\n",
        "# Aqu√≠ mostramos importancias para RandomForest/XGBoost si est√°n disponibles.\n",
        "\n",
        "def get_feature_names(preprocessor, num_cols, cat_cols):\n",
        "    num_features = num_cols\n",
        "    cat_encoder = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "    cat_features = cat_encoder.get_feature_names_out(cat_cols).tolist()\n",
        "    return num_features + cat_features\n",
        "\n",
        "model = best_pipe.named_steps[\"model\"]\n",
        "pre = best_pipe.named_steps[\"pre\"]\n",
        "\n",
        "if hasattr(model, \"feature_importances_\"):\n",
        "    feat_names = get_feature_names(pre, num_cols, cat_cols)\n",
        "    importances = pd.Series(model.feature_importances_, index=feat_names).sort_values(ascending=False)\n",
        "    top20 = importances.head(20)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    top20[::-1].plot(kind=\"barh\")\n",
        "    plt.title(\"Top 20 Importancias de Variables\")\n",
        "    plt.xlabel(\"Importancia\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"El modelo seleccionado no expone 'feature_importances_' (prueba con RandomForest o XGBoost).\")\n"
      ],
      "metadata": {
        "id": "bxoHHVRmxPJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (11) GUARDAR DATASET TRATADO Y MODELO\n",
        "# Exportar la versi√≥n procesada m√≠nima (X + y en un solo CSV) por si la necesitas\n",
        "processed = df.copy()\n",
        "processed.to_csv(\"telecom_churn_processed.csv\", index=False)\n",
        "print(\"üíæ Guardado telecom_churn_processed.csv\")\n",
        "\n",
        "# Guardar el modelo entrenado (pipeline completo) con joblib\n",
        "import joblib\n",
        "joblib.dump(best_pipe, \"modelo_churn_pipeline.joblib\")\n",
        "print(\"üíæ Guardado modelo_churn_pipeline.joblib\")\n",
        "\n",
        "# Descargar a tu PC (si corres en Colab)\n",
        "from google.colab import files\n",
        "files.download(\"telecom_churn_processed.csv\")\n",
        "files.download(\"modelo_churn_pipeline.joblib\")\n"
      ],
      "metadata": {
        "id": "j_j5Yb1pxQTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}